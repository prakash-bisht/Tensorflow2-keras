{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow2-12.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNwB0W8/RXwo+eR++f9GNsN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Noahbisht0/Tensorflow2-keras/blob/main/Tensorflow2_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31u9I2P7-wYK"
      },
      "source": [
        "import numpy as np \n",
        "import tensorflow as tf \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
        "from tensorflow.keras.optimizers import Adam \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,LSTM,Dense,Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXRApIotL-h5",
        "outputId": "3c106540-5f38-4038-e88e-81aa2681b11a"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "data=\"In the town of Athy one Jeremy Lanigan \\n Battered away til he hadnt a pound. \\nHis father died and made him a man again \\n Left him a farm and ten acres of ground. \\nHe gave a grand party for friends and relations \\nWho didnt forget him when come to the wall, \\nAnd if youll but listen Ill make your eyes glisten \\nOf the rows and the ructions of Lanigans Ball. \\nMyself to be sure got free invitation, \\nFor all the nice girls and boys I might ask, \\nAnd just in a minute both friends and relations \\nWere dancing round merry as bees round a cask. \\nJudy ODaly, that nice little milliner, \\nShe tipped me a wink for to give her a call, \\nAnd I soon arrived with Peggy McGilligan \\nJust in time for Lanigans Ball. \\nThere were lashings of punch and wine for the ladies, \\nPotatoes and cakes; there was bacon and tea, \\nThere were the Nolans, Dolans, OGradys \\nCourting the girls and dancing away. \\nSongs they went round as plenty as water, \\nThe harp that once sounded in Taras old hall,\\nSweet Nelly Gray and The Rat Catchers Daughter,\\nAll singing together at Lanigans Ball. \\nThey were doing all kinds of nonsensical polkas \\nAll round the room in a whirligig. \\nJulia and I, we banished their nonsense \\nAnd tipped them the twist of a reel and a jig. \\nAch mavrone, how the girls got all mad at me \\nDanced til youd think the ceiling would fall. \\nFor I spent three weeks at Brooks Academy \\nLearning new steps for Lanigans Ball. \\nThree long weeks I spent up in Dublin, \\nThree long weeks to learn nothing at all,\\n Three long weeks I spent up in Dublin, \\nLearning new steps for Lanigans Ball. \\nShe stepped out and I stepped in again, \\nI stepped out and she stepped in again, \\nShe stepped out and I stepped in again, \\nLearning new steps for Lanigans Ball. \\nBoys were all merry and the girls they were hearty \\nAnd danced all around in couples and groups, \\nTil an accident happened, young Terrance McCarthy \\nPut his right leg through miss Finnertys hoops. \\nPoor creature fainted and cried Meelia murther, \\nCalled for her brothers and gathered them all. \\nCarmody swore that hed go no further \\nTil he had satisfaction at Lanigans Ball. \\nIn the midst of the row miss Kerrigan fainted, \\nHer cheeks at the same time as red as a rose. \\nSome of the lads declared she was painted, \\nShe took a small drop too much, I suppose. \\nHer sweetheart, Ned Morgan, so powerful and able, \\nWhen he saw his fair colleen stretched out by the wall, \\nTore the left leg from under the table \\nAnd smashed all the Chaneys at Lanigans Ball. \\nBoys, oh boys, twas then there were runctions. \\nMyself got a lick from big Phelim McHugh. \\nI soon replied to his introduction \\nAnd kicked up a terrible hullabaloo. \\nOld Casey, the piper, was near being strangled. \\nThey squeezed up his pipes, bellows, chanters and all. \\nThe girls, in their ribbons, they got all entangled \\nAnd that put an end to Lanigans Ball.\"\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1 \n",
        "print(total_words)\n",
        "print(tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "263\n",
            "{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVGvvCrsL-l9"
      },
      "source": [
        "input_sequences = []\n",
        "for line in corpus:\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  for i in range(1,len(token_list)):\n",
        "    n_gram_sequences = token_list[:i+1]\n",
        "    input_sequences.append(n_gram_sequences)\n",
        "max_sequences_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences,maxlen=max_sequences_len,padding = 'pre'))\n",
        "xs,labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "ys = tf.keras.utils.to_categorical(labels,num_classes=total_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFaGiOkiL-qN",
        "outputId": "fd0363e6-6ce4-4d57-f254-24e242031668"
      },
      "source": [
        "print(tokenizer.word_index['in'])\n",
        "print(tokenizer.word_index['the'])\n",
        "print(tokenizer.word_index['town'])\n",
        "print(tokenizer.word_index['of'])\n",
        "print(tokenizer.word_index['athy'])\n",
        "print(tokenizer.word_index['one'])\n",
        "print(tokenizer.word_index['jeremy'])\n",
        "print(tokenizer.word_index['lanigan'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "2\n",
            "66\n",
            "8\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh9TE2qJL-tf",
        "outputId": "ad568690-d9a4-4697-e1b0-4cd0a5ff09a3"
      },
      "source": [
        "print(xs[6])\n",
        "print(ys[6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  0  0  4  2 66  8 67 68 69]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqoR8iMaL-vv",
        "outputId": "e9c21e55-7fd0-4fec-cfe2-4d3de76f710a"
      },
      "source": [
        "print(tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEUD7jj7L-yk",
        "outputId": "b6440b14-86e4-4ea7-ca6d-266f497b75dc"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words,64,input_length=max_sequences_len-1))\n",
        "model.add(Bidirectional(LSTM(20)))\n",
        "model.add(Dense(total_words,activation=\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])\n",
        "history = model.fit(xs,ys,epochs=200,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "15/15 [==============================] - 3s 9ms/step - loss: 5.5712 - accuracy: 0.0078\n",
            "Epoch 2/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 5.5496 - accuracy: 0.0527\n",
            "Epoch 3/200\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 5.5038 - accuracy: 0.0422\n",
            "Epoch 4/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 5.3521 - accuracy: 0.0529\n",
            "Epoch 5/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 5.1478 - accuracy: 0.0402\n",
            "Epoch 6/200\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 5.0801 - accuracy: 0.0492\n",
            "Epoch 7/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 5.0427 - accuracy: 0.0580\n",
            "Epoch 8/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 5.0439 - accuracy: 0.0378\n",
            "Epoch 9/200\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.9810 - accuracy: 0.0745\n",
            "Epoch 10/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.9828 - accuracy: 0.0569\n",
            "Epoch 11/200\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.8439 - accuracy: 0.0729\n",
            "Epoch 12/200\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.8800 - accuracy: 0.0522\n",
            "Epoch 13/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.8199 - accuracy: 0.0619\n",
            "Epoch 14/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.8179 - accuracy: 0.0632\n",
            "Epoch 15/200\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.6993 - accuracy: 0.0645\n",
            "Epoch 16/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.6516 - accuracy: 0.0600\n",
            "Epoch 17/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.6186 - accuracy: 0.0616\n",
            "Epoch 18/200\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.5827 - accuracy: 0.0732\n",
            "Epoch 19/200\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.5501 - accuracy: 0.0697\n",
            "Epoch 20/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.5447 - accuracy: 0.0977\n",
            "Epoch 21/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.4428 - accuracy: 0.0921\n",
            "Epoch 22/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.4936 - accuracy: 0.0854\n",
            "Epoch 23/200\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.4077 - accuracy: 0.0866\n",
            "Epoch 24/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.3984 - accuracy: 0.0866\n",
            "Epoch 25/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.3891 - accuracy: 0.0931\n",
            "Epoch 26/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.2723 - accuracy: 0.1030\n",
            "Epoch 27/200\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 4.2914 - accuracy: 0.1029\n",
            "Epoch 28/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.1813 - accuracy: 0.1037\n",
            "Epoch 29/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.1867 - accuracy: 0.1349\n",
            "Epoch 30/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.1468 - accuracy: 0.1288\n",
            "Epoch 31/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.1567 - accuracy: 0.1374\n",
            "Epoch 32/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.0713 - accuracy: 0.1538\n",
            "Epoch 33/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.0061 - accuracy: 0.1556\n",
            "Epoch 34/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.0748 - accuracy: 0.1412\n",
            "Epoch 35/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.8887 - accuracy: 0.1822\n",
            "Epoch 36/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.9196 - accuracy: 0.1590\n",
            "Epoch 37/200\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.8813 - accuracy: 0.1703\n",
            "Epoch 38/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.8310 - accuracy: 0.1767\n",
            "Epoch 39/200\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.8027 - accuracy: 0.1938\n",
            "Epoch 40/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.7977 - accuracy: 0.2141\n",
            "Epoch 41/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.6941 - accuracy: 0.2277\n",
            "Epoch 42/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.6989 - accuracy: 0.2043\n",
            "Epoch 43/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.6330 - accuracy: 0.2380\n",
            "Epoch 44/200\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.6508 - accuracy: 0.2387\n",
            "Epoch 45/200\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.6196 - accuracy: 0.2439\n",
            "Epoch 46/200\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.5584 - accuracy: 0.2143\n",
            "Epoch 47/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.4723 - accuracy: 0.2592\n",
            "Epoch 48/200\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.4985 - accuracy: 0.2380\n",
            "Epoch 49/200\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.3921 - accuracy: 0.2818\n",
            "Epoch 50/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.3773 - accuracy: 0.3081\n",
            "Epoch 51/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.3538 - accuracy: 0.2939\n",
            "Epoch 52/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.2955 - accuracy: 0.3150\n",
            "Epoch 53/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.2736 - accuracy: 0.3068\n",
            "Epoch 54/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.2401 - accuracy: 0.3164\n",
            "Epoch 55/200\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 3.2345 - accuracy: 0.3474\n",
            "Epoch 56/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.1214 - accuracy: 0.3942\n",
            "Epoch 57/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.1205 - accuracy: 0.3284\n",
            "Epoch 58/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.1340 - accuracy: 0.3811\n",
            "Epoch 59/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.0283 - accuracy: 0.4094\n",
            "Epoch 60/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.9958 - accuracy: 0.3926\n",
            "Epoch 61/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.9850 - accuracy: 0.4283\n",
            "Epoch 62/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.0075 - accuracy: 0.3905\n",
            "Epoch 63/200\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.8980 - accuracy: 0.4322\n",
            "Epoch 64/200\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.8047 - accuracy: 0.4670\n",
            "Epoch 65/200\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.7966 - accuracy: 0.4710\n",
            "Epoch 66/200\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.8564 - accuracy: 0.4511\n",
            "Epoch 67/200\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.8338 - accuracy: 0.4528\n",
            "Epoch 68/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.7418 - accuracy: 0.4733\n",
            "Epoch 69/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.6892 - accuracy: 0.4629\n",
            "Epoch 70/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.7930 - accuracy: 0.4137\n",
            "Epoch 71/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.6428 - accuracy: 0.4845\n",
            "Epoch 72/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.6275 - accuracy: 0.4763\n",
            "Epoch 73/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.5706 - accuracy: 0.5176\n",
            "Epoch 74/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.5594 - accuracy: 0.5046\n",
            "Epoch 75/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.5210 - accuracy: 0.5282\n",
            "Epoch 76/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.4701 - accuracy: 0.5511\n",
            "Epoch 77/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.4875 - accuracy: 0.5463\n",
            "Epoch 78/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.4576 - accuracy: 0.5764\n",
            "Epoch 79/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.4316 - accuracy: 0.5306\n",
            "Epoch 80/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.3939 - accuracy: 0.5495\n",
            "Epoch 81/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.3792 - accuracy: 0.5789\n",
            "Epoch 82/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.3723 - accuracy: 0.5759\n",
            "Epoch 83/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.3122 - accuracy: 0.6025\n",
            "Epoch 84/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.2767 - accuracy: 0.6181\n",
            "Epoch 85/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.2916 - accuracy: 0.5717\n",
            "Epoch 86/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.2564 - accuracy: 0.6290\n",
            "Epoch 87/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.2485 - accuracy: 0.5979\n",
            "Epoch 88/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.2463 - accuracy: 0.5640\n",
            "Epoch 89/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.1805 - accuracy: 0.6167\n",
            "Epoch 90/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.1627 - accuracy: 0.6060\n",
            "Epoch 91/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.1260 - accuracy: 0.6239\n",
            "Epoch 92/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.1880 - accuracy: 0.5927\n",
            "Epoch 93/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.0755 - accuracy: 0.6428\n",
            "Epoch 94/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.1237 - accuracy: 0.6372\n",
            "Epoch 95/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.0785 - accuracy: 0.6342\n",
            "Epoch 96/200\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 2.0298 - accuracy: 0.6072\n",
            "Epoch 97/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.9544 - accuracy: 0.6541\n",
            "Epoch 98/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.9821 - accuracy: 0.6544\n",
            "Epoch 99/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.8992 - accuracy: 0.6720\n",
            "Epoch 100/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.9380 - accuracy: 0.6562\n",
            "Epoch 101/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.8659 - accuracy: 0.6653\n",
            "Epoch 102/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.8500 - accuracy: 0.6750\n",
            "Epoch 103/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.8647 - accuracy: 0.6729\n",
            "Epoch 104/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.9659 - accuracy: 0.6499\n",
            "Epoch 105/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.9058 - accuracy: 0.6425\n",
            "Epoch 106/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.8197 - accuracy: 0.6667\n",
            "Epoch 107/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.8737 - accuracy: 0.6481\n",
            "Epoch 108/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.7715 - accuracy: 0.7239\n",
            "Epoch 109/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.7271 - accuracy: 0.7446\n",
            "Epoch 110/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.7126 - accuracy: 0.7168\n",
            "Epoch 111/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.6980 - accuracy: 0.7505\n",
            "Epoch 112/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.7088 - accuracy: 0.7356\n",
            "Epoch 113/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.7133 - accuracy: 0.7086\n",
            "Epoch 114/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.6196 - accuracy: 0.7385\n",
            "Epoch 115/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.6862 - accuracy: 0.7275\n",
            "Epoch 116/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.6195 - accuracy: 0.7419\n",
            "Epoch 117/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.6124 - accuracy: 0.7674\n",
            "Epoch 118/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.5861 - accuracy: 0.7541\n",
            "Epoch 119/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.5697 - accuracy: 0.7411\n",
            "Epoch 120/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.5577 - accuracy: 0.7269\n",
            "Epoch 121/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.5428 - accuracy: 0.7487\n",
            "Epoch 122/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.5481 - accuracy: 0.7699\n",
            "Epoch 123/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.4654 - accuracy: 0.7785\n",
            "Epoch 124/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.4130 - accuracy: 0.7944\n",
            "Epoch 125/200\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 1.4052 - accuracy: 0.8111\n",
            "Epoch 126/200\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 1.4449 - accuracy: 0.7827\n",
            "Epoch 127/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.4774 - accuracy: 0.7772\n",
            "Epoch 128/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.4425 - accuracy: 0.7788\n",
            "Epoch 129/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.4199 - accuracy: 0.7773\n",
            "Epoch 130/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.4105 - accuracy: 0.7896\n",
            "Epoch 131/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.4208 - accuracy: 0.7715\n",
            "Epoch 132/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.4238 - accuracy: 0.7634\n",
            "Epoch 133/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.3865 - accuracy: 0.7831\n",
            "Epoch 134/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.4621 - accuracy: 0.7462\n",
            "Epoch 135/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.4405 - accuracy: 0.7491\n",
            "Epoch 136/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.3786 - accuracy: 0.8126\n",
            "Epoch 137/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.3563 - accuracy: 0.7852\n",
            "Epoch 138/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.4809 - accuracy: 0.7334\n",
            "Epoch 139/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.3605 - accuracy: 0.7534\n",
            "Epoch 140/200\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 1.3250 - accuracy: 0.7851\n",
            "Epoch 141/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.2907 - accuracy: 0.8067\n",
            "Epoch 142/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.2756 - accuracy: 0.8186\n",
            "Epoch 143/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.2346 - accuracy: 0.8240\n",
            "Epoch 144/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.2248 - accuracy: 0.8370\n",
            "Epoch 145/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.2653 - accuracy: 0.7790\n",
            "Epoch 146/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.2408 - accuracy: 0.8177\n",
            "Epoch 147/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.1920 - accuracy: 0.8348\n",
            "Epoch 148/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.2313 - accuracy: 0.8040\n",
            "Epoch 149/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.1884 - accuracy: 0.8300\n",
            "Epoch 150/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.1143 - accuracy: 0.8447\n",
            "Epoch 151/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.1366 - accuracy: 0.8434\n",
            "Epoch 152/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.1200 - accuracy: 0.8566\n",
            "Epoch 153/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.1091 - accuracy: 0.8574\n",
            "Epoch 154/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.1136 - accuracy: 0.8249\n",
            "Epoch 155/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.0935 - accuracy: 0.8573\n",
            "Epoch 156/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.0467 - accuracy: 0.8510\n",
            "Epoch 157/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.0468 - accuracy: 0.8516\n",
            "Epoch 158/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.0975 - accuracy: 0.8355\n",
            "Epoch 159/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.0359 - accuracy: 0.8484\n",
            "Epoch 160/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.0546 - accuracy: 0.8703\n",
            "Epoch 161/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.0050 - accuracy: 0.8807\n",
            "Epoch 162/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.0492 - accuracy: 0.8434\n",
            "Epoch 163/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.0196 - accuracy: 0.8583\n",
            "Epoch 164/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.9730 - accuracy: 0.8849\n",
            "Epoch 165/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.9708 - accuracy: 0.8770\n",
            "Epoch 166/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.9655 - accuracy: 0.8668\n",
            "Epoch 167/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.9826 - accuracy: 0.8685\n",
            "Epoch 168/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.0070 - accuracy: 0.8573\n",
            "Epoch 169/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.9502 - accuracy: 0.8769\n",
            "Epoch 170/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.9160 - accuracy: 0.8784\n",
            "Epoch 171/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.8935 - accuracy: 0.8827\n",
            "Epoch 172/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.8954 - accuracy: 0.8817\n",
            "Epoch 173/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.8972 - accuracy: 0.8853\n",
            "Epoch 174/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.8831 - accuracy: 0.8825\n",
            "Epoch 175/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.8955 - accuracy: 0.8895\n",
            "Epoch 176/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.8764 - accuracy: 0.8874\n",
            "Epoch 177/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.8620 - accuracy: 0.8824\n",
            "Epoch 178/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.9412 - accuracy: 0.8667\n",
            "Epoch 179/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.8544 - accuracy: 0.8983\n",
            "Epoch 180/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.8325 - accuracy: 0.8893\n",
            "Epoch 181/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.8248 - accuracy: 0.9092\n",
            "Epoch 182/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.8311 - accuracy: 0.9015\n",
            "Epoch 183/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.8435 - accuracy: 0.8963\n",
            "Epoch 184/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7951 - accuracy: 0.9114\n",
            "Epoch 185/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7796 - accuracy: 0.9090\n",
            "Epoch 186/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.8270 - accuracy: 0.8954\n",
            "Epoch 187/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.8035 - accuracy: 0.9101\n",
            "Epoch 188/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7841 - accuracy: 0.8936\n",
            "Epoch 189/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.8634 - accuracy: 0.8773\n",
            "Epoch 190/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.7510 - accuracy: 0.9084\n",
            "Epoch 191/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7505 - accuracy: 0.9256\n",
            "Epoch 192/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.7498 - accuracy: 0.8997\n",
            "Epoch 193/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7755 - accuracy: 0.8837\n",
            "Epoch 194/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7230 - accuracy: 0.9051\n",
            "Epoch 195/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7628 - accuracy: 0.8762\n",
            "Epoch 196/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7338 - accuracy: 0.9063\n",
            "Epoch 197/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.6909 - accuracy: 0.9157\n",
            "Epoch 198/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6968 - accuracy: 0.8967\n",
            "Epoch 199/200\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7284 - accuracy: 0.8867\n",
            "Epoch 200/200\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.6676 - accuracy: 0.9169\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISZcS39jL-1B"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_graph(history,string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "J5r4oERKL-36",
        "outputId": "845cce00-65b6-4c7e-8f7c-19652223e472"
      },
      "source": [
        "plot_graph(history,'accuracy')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l14xdY9-L-8U",
        "outputId": "c1b4fae8-5bd4-44c7-9197-66d9825dd2ab"
      },
      "source": [
        "seed_text = \"Noah went to dublin\"\n",
        "next_words = 100\n",
        "for _ in range(next_words):\n",
        "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "  token_list = pad_sequences([token_list],maxlen=max_sequences_len-1,padding='pre')\n",
        "  predicted = model.predict_classes(token_list,verbose=0)\n",
        "  output_word = \"\"\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "    if index == predicted:\n",
        "      output_word = word\n",
        "  seed_text += \" \" + output_word\n",
        "print(seed_text) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Noah went to dublin the stretched the ogradys might hall eyes wall youd girls together were all chaneys were hearty wall hearty at ground relations wall suppose relations girls call ground ground wall gray ground ground ground ground wall girls up up mavrone up up up a meelia murther murther murther murther eyes ground mavrone up up me he pound rose cask hall rose rose table table suppose mavrone up up up in couples and groups groups groups groups mchugh relations girls up up up a and big phelim mchugh mchugh mchugh relations suppose relations girls were ladies hall stretched ground ground ground wall\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}